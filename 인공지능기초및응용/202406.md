## 드림부스

- 3~5장의 적은 이미지로 생성 모델을 학습할 수 있다.
- 기존 연구에선 많은 양의 데이터를 필요로 했고, Fidelity(실제 모습과 일치도) 나 Context(새로운 설명)에 대한 생성의 한계점이 존재
- 제안 방법
    - Stable Diffusion 모델을 Custom 데이터 활용, 효율적으로 파인 튜닝. 즉 Stable Diffusion을 좀 더 개인화된 데이터로 다시 훈련
    - 인풋으로 3~5장의 이미지와 subject’s class name (예를 들어 Dog), 사전학습된 T2I 모델을 드림부스에 입력
    - 아웃풋으로 Unique identifier 출력 “V”, 개인화된 T2I 모델
    - 이제 이 개인화된 모델에 A [V] dog in the beach 라고 입력 시 바다에 있는 강아지를 그려줌
- Reconstruction Loss
    - 적은 이미지로 특징을 잘 살려내는 생성모델 학습을 위한 소실함수
    - A [V] dog 형태의 텍스트 프롬프트를 사용해 입력했던 3~5장의 이미지를 생성하도록 모델을 학습
    - [V] 에는 해당 이미지의 특징 등이 들어갈 수 있음
    - A [V] 형태로 학습하지 않는 이유는, 학습시간이 오래 걸리고 성능도 보장이 어려워서.
- Prior Preservation Loss
    - Class 정보를 잃어버리지 않기 위한 Loss Function
    - Class 정보만으로 이미지를 생성하는 Term 추가, Class 정보 잊지 않음
    - A dog 형태의 프롬프트로 Stabld Diffusion 등에서 랜덤한 이미지 생성 후 파인 튜닝 할 때 A dog로부터 생성된 데이터 만들도록 모델 학습
- 한계점
    - Incorrect Context Synthesis (잘못된 문맥 생성) : 사전학습 모델이 보유한 정보가 부족하거나, 객체와 장소를 동시생성하기 어려운 상황 존재
    - Context-appearance Entangling (문맥-외형 얽힘) : 드문 경우를 생성하면 외형 변환이 나타남
    - Overfitting (과적합) : 입력 이미지의 형태에 의존하게 되어 새로운  이미지 생성시 다양성이 부족
  
## FairDeDup

- Vision-Language 모델의 빠른 학습과 불공정성 문제 개선을 위한 방법 제안
    - Web-scale의 대용량 데이터를 50%만 활용, 정확도 유지 및 공정성 증가
    - 데이터 Embed, Clustering, Prune(가지치기)
- 관련 연구로 VLP 모델이 있으며, 웹에 있는 방대한 데이터로 편향 포함 있을 수 있음
- Fairness를 고려한 인공지능이란, 공정하고 편향이 발생하지 않는 인공지능이며, 보호속성에 따라 정확도의 차이가 나타나지 않는 인공지능
- 기존 기술의 문제점
    - 학습 데이터가 많아 오래걸리고 매우 비쌈
    - 데이터 크롤링 과정에서  파일명만 다른 데이터가 받아질 수 있음
    - 이를 SemDeDup 기술을 통해 학습 비용을 절반으로 줄일 수 있음
    - 단, SemDeDup은 복제데이터 삭제 과정에서 편향 문제가 강화됨
- SemDeDup의 데이터 삭제 방법
    1. CLIP 모델로 데이터 특징(embeddings) 추출
    2. K-Means Clustering으로 유사 데이터 그룹화
    3. 같은 그룹 안에서 유사 데이터를 이웃화 (임계치 설정)
    4. 각 그룹의 중심으로부터 가장 먼 샘플만 (한 이웃 그룹당 하나의 데이터만) 남김
    5. 유사 데이터가 없는 경우에도 보존
    - 이는 중심에서 가장 먼 샘플이 가장 독특한 샘플이라고 가정한 것
    - **Subgroup**을 고려하지 않아서, 특정 group의 샘플이 버려지는 경우 발생
- FairDeDup
    1. SemDeDup의 3번까지 동일
    2. 클러스터 내 샘플과 Subgroup간 Cosine 유사도를 측정
        - 코사인 유사도 : 두 벡터간의 방향이 얼마나 비슷한지
        - 클러스터 내에서 각 이미지들과 남성 subgroup, 여성 subgroup 간의 유사도 계산
    3. 가장  낮은 평균 유사도를 보이는 Subgroup을 고르고, 그 안에서 가장 높은 유사도를 가지는 샘플을 보존
    - 이는 Subgroup을 고려하므로 Data Balance 유지
    - 여기서 Subgroup이란 성별, 인종, 나이 등
- 한계점
    - 기존 데이터를 50% 축소시키는 과정에선 어떤 이유로 공정성에 문제가 발생하는지 명확한 근거와 이유가 없음
    - 클러스터링 과정에서 이미 성별이나 인종이 구분되었다면, 클러스터 내 Subgroup간 다양성 개선이 의미 없어짐
    - CLIP 등 특징 추출 모델이 편향된 경우를 고려해야 함
    - 이 논문은 VLP 모델에 초점을 맞춰 일반화 성능 보장을 위해선 추가 연구 필요

## PromptCap

- Knowledge-based VQA 문제를 다루는 연구
    - Knowledge-based VQA : 이미지 내에서 확인할 수 없는 추가 지식을 질문으로 요구하는 질문 - 응답으로 구성된 Task
    - 해결 방법 : 외부 지식 활용 (Knowledge graph, Wikipedia), LLM 활용
- GPT-3를 활용해 성능 개선
- 이미지와 텍스트 질문이 입력되었을 때, 응답을 예측하는 Task
- 기존 기술의 문제점
    - SOTA인 OFA 모델이 생성하는  이미지 캡션 정보로는 질문 응답이 어려움
- 제안 방법
    - KVQA 문제 해결에 도움이 되는 Image Captioning Model인 PromptCap을 통해 응답 성능 높이기
    - PromptCap 모델의 학습데이터를 GPT-3로 합성해 모델 학습
    - GPT-3를 활용해 학습 데이터 생성 (이미지 캡션 데이터)
    - Prompt에 이하의 정보를 입력
        - Task Instruction : 질의응답에 도움되는 컨텍스트(문맥)를 요약하라
        - 원본 Context : 데이터셋에 존재하는 캡션(설명문)
        - Question : 이미지에 대한 질문
        - 응답 : 데이터에 존재하는 정답
        - Summary : 사람이 수기로 작성한 응답
    - GPT의 In-Context Learning 우수성을 활용
        - 총 20개의 예시를 주고, 새로운 Summary(요약) 작성
        - In-Context Learning은 GPT에 N개의 예시를 제공하고 답변을 응답받는 방식으로, example이 주어진 경우 해당 내용을 참고해 더 높은 정확도 응답 제공
- 제안 단계
    1. PromptCap으로부터 질의응답에 도움되는 Context 추출
    2. 나온 Context를 함께하여 GPT-3의 In-context Learning을 통해 개선된 응답을 생성
- 한계점
    - PromptCap에서 도움되는 정보가 제공되지 않거나, 할로시네이션 발생 시 실패
    - 모호한 질문에 대한 응답이 어렵고, 정확한 정보 전달 실패
    - 그러나 최근에는 응답 개선, In-context Learning 없이 응답 불가