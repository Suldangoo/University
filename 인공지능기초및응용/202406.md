## 드림부스

- 3~5장의 적은 이미지로 생성 모델을 학습할 수 있다.
- 기존 연구에선 많은 양의 데이터를 필요로 했고, Fidelity(실제 모습과 일치도) 나 Context(새로운 설명)에 대한 생성의 한계점이 존재
- 제안 방법
    - Stable Diffusion 모델을 Custom 데이터 활용, 효율적으로 파인 튜닝. 즉 Stable Diffusion을 좀 더 개인화된 데이터로 다시 훈련
    - 인풋으로 3~5장의 이미지와 subject’s class name (예를 들어 Dog), 사전학습된 T2I 모델을 드림부스에 입력
    - 아웃풋으로 Unique identifier 출력 “V”, 개인화된 T2I 모델
    - 이제 이 개인화된 모델에 A [V] dog in the beach 라고 입력 시 바다에 있는 강아지를 그려줌
- Reconstruction Loss
    - 적은 이미지로 특징을 잘 살려내는 생성모델 학습을 위한 소실함수
    - A [V] dog 형태의 텍스트 프롬프트를 사용해 입력했던 3~5장의 이미지를 생성하도록 모델을 학습
    - [V] 에는 해당 이미지의 특징 등이 들어갈 수 있음
    - A [V] 형태로 학습하지 않는 이유는, 학습시간이 오래 걸리고 성능도 보장이 어려워서.
- Prior Preservation Loss
    - Class 정보를 잃어버리지 않기 위한 Loss Function
    - Class 정보만으로 이미지를 생성하는 Term 추가, Class 정보 잊지 않음
    - A dog 형태의 프롬프트로 Stabld Diffusion 등에서 랜덤한 이미지 생성 후 파인 튜닝 할 때 A dog로부터 생성된 데이터 만들도록 모델 학습
- 한계점
    - Incorrect Context Synthesis (잘못된 문맥 생성) : 사전학습 모델이 보유한 정보가 부족하거나, 객체와 장소를 동시생성하기 어려운 상황 존재
    - Context-appearance Entangling (문맥-외형 얽힘) : 드문 경우를 생성하면 외형 변환이 나타남
    - Overfitting (과적합) : 입력 이미지의 형태에 의존하게 되어 새로운  이미지 생성시 다양성이 부족