# 1주차

- 논문 / 프로젝트 발표 중 택 1, 모두 참여 시 +5점
    - 프로젝트 : 인공지능 모델 및 활용기술 개발
    - 논문 : 학술대회명, 제목
    - 관련 연구, 기존 기술 문제점, 기존 기술 극복법, 신규 기술 한계점, 질의응답 모두 포함
    - 발표 시간 15분, 질의응답 5분

- 논문의 경우 23년도 이후 AI관련 학술대회 정규논문으로 제한
    - https://openaccess.thecvf.com/menu
    - 정규논문으로 제한, 워크숍 논문 발표 시 3편 이상 발표
- 프로젝트 기존기술 : 23년도 이후 AI관련 학술대회 정규논문으로 제한
    - 가급적 소스코드가 공개된 기술로
    - 소스코드 구현

- 수학, 머신러닝에 대한 기본 지식이 필요

- 논문에 나오는 용어들은 라틴어 약어이므로 PPT 참고
- 읽는 순서
    1. 제목
    2. Abstract (초록)
    3. Conclusion (결론)
    4. Result (결과)
    5. Introduction (서론)
    6. Method & Result (방법 및 결과)
- 논문의 제목 및 초록을 통해 다음과 같은 내용 파악 후 상세 읽기
    - 대표 주제
    - 기존 연구의 문제점
    - 간략한 아이디어
    - 실험에 사용한 데이터
    - 결과 성능
    - 한계점
- 논문 구글 스칼라에 검색하여 인용 수 확인
- 서론의 경우엔 간단한 개념만 요약해 보기

# 2주차

## 인공지능의 역사

- 인공지능(AI)의 정의 : 인간의 학습능력, 추론능력, 지각능력을 인공적으로 구현하려는 컴퓨터 과학의 세부분야 중 하나
    - AI 내부 개념으로 머신 러닝
    - 머신 러닝 내부 개념으로 딥 러닝
    - 딥 러닝 내부 개념으로 파운데이션 모델
    - 파운데이션 모델 내부 개념으로 LLM
- 1950년 컴퓨터의 시초인 **튜링머신**을 앨런 튜링이 개발
    - 기계가 인간과 얼마나 유사한 응답을 내는지 확인하기 위한 튜링 테스트를 고안
    - 사람과 원숭이 사진을 보고 어떤게 사람인지 대답해내는 것과 비슷
- 1956년 존 매카시가 **인공지능**이라는 용어를 정의
- 1957년 인공 신경망 모형의 하나인 **퍼셉트론**(Perceptron) 등장
    - 입력 데이터에 가중치를 곱하고 활성화함수 통과 후 출력 값을 내는 구조
- 초기 컴퓨터는 bit 연산을 통해 데이터를 처리
    - 1과 0으로 이루어진 전기가 흐르냐 안 흐르냐
    - 대표 연산자로 NOT, AND, OR, XOR
    - 퍼셉트론으로는 AND, OR을 해결할 수 있으나 XOR을 해결할 수 없었음
- 1986년 **다층 퍼셉트론**(Multi Layer Perceptron; **MLP**) 등장 (제프리 힌튼)
    - 입력층과 출력층 사이에 은닉층을 추가해 기존에 풀지 못했던 XOR 문제 해결
- 퍼셉트론과 오차역전파 등장 이후 CNN 및 RNN 기반의 인공지능 기술이ㅣ 발전함
- 2012년 ILSVRC 대회에서 CNN 기반 모델인 AlexNet으로 1위를 차지 (제프리 힌튼)
    - 2015년부터 이미지 분류 점수가 인간을 추월하게 됨
- 2014년 **GANs**의 등장으로 인공지능기반 생성모델의 잠재력을 확인
    - 서로 다른 목적을 가진 두 네트워크 학습인 적대적 학습
    - 이때부터 가짜 데이터를 만들어내기 시작 (사람의 얼굴을 생성함)
    - 이후 GAN 기반의 생성기술이 급격히 발전해 Diffusion 기반의 기술로 대체되었다
- 2017년 **Transformer**의 등장으로 자연어 분류 및 생성 기술에도 급격한 기술 발전
    - ChatGPT도 Transformer 기반 기술 중 하나
    - 이후 모든 텍스트 기반의 인공지능 기술은 거의 모든것이 트랜스포머를 기반으로 둔 기술
- 2024년 CES에서 소개된 IT트랜드 On-device AI
    - 네트워크 연결 없이 반도체 칩으로 AI 모델을 구동시키기 위한 기술
    - 갤럭시 S24부턴 AI 실시간 번역기능을 탑재해 출시
    - AI 기술을 이곳저곳에서 쓰고싶어도 대부분 비용 문제가 발생해서 사용이 어려움
    - 기술은 있지만 하드웨어가 없어서 사용을 못하고 있었는데 온디바이스가 되면 해결됨

## 인공지능 기초 및 용어

- 규칙 기반(Rule-based) 인공지능
    - 학습이 불필요함
    - A를 누르면 B를 실행
- 학습기반(Learning-based) 인공지능
    - 머신러닝, 딥러닝은 학습기반 기술에 포함
    - 데이터(지식)를 기반으로 특성 추출 및 분류(분석)를 통해 결과를 출력하는 방식
    - 인간이 직접 특성을 추출하면 머신 러닝, 컴퓨터로 추출하면 딥러닝

- 정형 데이터 (Structured Data)
    - 정해진 틀/형태에 맞게 저장된 데이터
- 반정형 데이터
    - 데이터 모델을 따르지는 않는 형태이나 구조화된 데이터
- 비정형 데이터 (Unstructured Data)
    - 특정 형태나 데이터 모델 없이 저장된 데이터

- Zero-shot Learning
    - 학습하지 않은 범주의 데이터를 분류
- One-shot Learning
    - 1개의 샘플만 학습하여 사용하는 모델
- Few-shot Learning
    - N개 (주로 1~5) 데이터만 사용하여 학습한 모델

- Classification (이미지, 오디오, 텍스트 분류)
    - 데이터를 미리 정의된 카테고리로 분류
    - 내일 날씨는 추울까 / 따듯할까?
- Regression (회귀, 수치 예측)
    - 데이터에 기반해 연속적인 수치(Value)를 예측
    - 내일 날씨는 몇 도일까?

- Pattern Recognition (얼굴, 지문, 음성인식)
    - 데이터에서 패턴이나 규칙을 식별
- Attribute Classification (속성정보 분류)
    - 객체의 여러 속성을 분류하여 정보를 구분

- Clustering (군집화, 비슷한 그룹끼리 뭉침)
    - 유사한 특성을 가진 데이터 포인트들을 그룹화
    - 여러가지 얼굴 인식 포인트가 있을 때 다르게 찍힌 얼굴도 동일인물이라고 판단하는 범위
    - 아이폰 갤러리에 사람 얼굴 그룹
- Detection (객체 검출 = 위치 + 레이블정보 분류)
    - 객체의 위치를 찾고 해당 객체를 분류
    - YOLO로 사진 안에서 사람, 자동차 등 식별
- Localization (상세한 위치 파악)
    - 정보의 정확한 위치를 식별
    - 어느 한 사물에서 일부 흠집같은 아주 세밀한 부분, 비정상 영역을 정확하게 식별

- Generation (생성)
    - 이미지, 텍스트, 오디오, 비디오 생성 등 데이터를 생성
- Translation (변환, text2img, img2img, TTS)
    - 생성 기술 중 한 가지 방식으로, 한 형식의 데이터를 다른 형식으로 변환
    - TTS (Text to Speach)

- Supervised Learning (지도학습)
    - 레이블이 지정된 훈련 데이터를 사용하여 모델을 학습
    - 분류해야할 테이블이 있고, 분류될 개체들의 각각 정답들이 모두 주어져있을 때 분류하기
- Semi-Supervised Learning (반지도학습)
    - 소량의 레이블이 지정된 데이터와 대량의 레이블이 없는 데이터를 함께 사용하여 모델 학습
    - 몇몇 데이터들은 정답이 있으나, 몇몇 데이터는 알려주지 않았을 때 그걸 분류해냄
- Unsupervised Learning (비지도학습)
    - 레이블이 지정되지 않은 데이터를 사용해 모델 학습
    - 전혀 정답을 알려주지 않아도 특징을 잡아내 연관된 것들끼리 분류

- Self-Supervised Learning (자기지도학습)
    - 데이터 내에서 레이블을 스스로 만들어 해당 레이블 데이터를 활용하여 모델학습
    - 이전 정보에서 다음으로 이어지는 단어들을 수집, 예측
    - Mask된 영역에 무엇이 들어갈지 예측
- Reinforcement Learning (강화학습)
    - 환경과의 상호작용을 통해 얻은 보상을 기반으로 최적의 결정 또는 경로 학습
    - 반복적으로 학습하며 더 나은 방향을 찍을 때마다 좋은 보상을 지급
- Continual Learning (연속학습)
    - 모델이 새로운 데이터 또는 작업을 지속적으로 학습하면서 과거에 학습한걸 잊지 않도록 학습
    - 학습 테스크를 나누어 1번부터 50번까지 학습, 다음엔 1번부터 60번까지 학습…

- Pre-train (사전학습)
    - 대용량 데이터 기반의 모델 학습
    - 빅데이터를 활용하여 하나의 모델을 생성
- Fine-Tuning (파인튜닝)
    - 대용량 데이터 기반 모델을 활용, 일반적으로는 소규모 데이터로 목적에 맞게 모델 재학습
    - 주목할 부분만 특별히 해석하거나, 필요한 데이터를 추가로 학습하는 등 미세 조정
    - 층 100개중 앞 30층만 변형, 뒤 70층은 고정하는 방식
    - 전이학습(Transfer Learning)이라는 미세 조정, 파인 튜닝

- Split (데이터 분할)
    - 인공지능 모델 개발 시 전체 데이터를 학습, 테스트 데이터로 구분하여 사용
    - 비율은 정해지지 않았으며 학습, 검증, 테스트로 구분하는 경우도 있고 검증은 모델 수렴을 확인하는데 사용함
    - 대부분의 공인 데이터는 학습  데이터와 테스트 데이터를 별개로 구분
- K-fold-cross-validation
    - 데이터를 K분할하여 교차검증
    - 이러면 모든 데이터에 대해 학습 / 테스트 구분이 가능해짐
    - 즉, 우연히 일정 방향으로 일반화된 결과가 나오지 않게 됨
        - Split마다 모델이 각각 하나씩 만들어짐
        - 여러 모델들을 만들어 평균 정확률이 가장 높은 것을 사용

---

## Numpy

- 임포트 구문

```python
import numpy as np
```

## Tensor

- 파이토치에서 텐서(Tensor)는 기본적인 수치 연산을 위한 주요 데이터 구조
- 임포트 구문

```python
import torch
```

# 3주차

- 초기 인공지능이란건 특정 문제상황에서 답을 자동으로 찾아주는 것
- 생성형 AI가 아닌 분류 AI
- 초기엔 AND, OR 문제정도만 푸는 AI인 퍼셉트론만 있음
- 점점 현대의 실제 문제들을 푸는 RNN, CNN이 등장

---

- 학습은 데이터로부터 모델을 학습, 이를 통해 예측 및 결정을 할 수 있도록 하는 기술의 집합을 의미함.

```jsx
y = f(x)
```

- 함수 f가 **모델**, 데이터로 f를 알아내는 과정을 **학습**, f로부터 y를 얻는 과정을 **예측**이라 칭함.
- 모델 학습은 일반적으로 다음과 같이 구성됨
    - 데이터 수집 → 모델 선택 → 학습 → 예측

## 퍼셉트론

- 입력층 : 입력 값을 받아들이는 층
- 노드 : 입력 값의 가중합과 활성화를 결정하는 층
- 출력층 : 퍼셉트론의 출력 값을 나타내는 층
- 활성화 함수
    - 퍼셉트론에서는 출력값을 다음 퍼셉트론으로 넘기는 과정에 변환을 적용하기 위한 함수
    - 모델의 복잡도를 높이기 위해 사용 (복잡할 수록 더 다양한 문제 해결)
    - 활성화 함수는 비선형 구조(Non-Linear)로 이루어짐
    - 시그모이드 함수 (음수라면 0.5 이하, 양수라면 0.5이상)
    - 리니어 함수는 가산성 및 동차성을 만족해야 함
- 딥러닝 모델의 경우 ReLU기반의 활성화 함수를 가장 많이 사용함
- 결정경계를 통해서 데이터를 분류
    - 신경망 출력 경계 값으로, 결정경계보다 큰 값은 1로, 작은 값은 0으로 분류

## Multi Layer Perceptron

- 다층 신경망(MLP)로 단층 신경망의 한계 (XOR문제) 극복하기
    - 하나의 직선으로는 분리가 불가능
    - 두개의  선으로 분류가  된다
- 단층 신경망과 다층 신경망의 차이는, 은닉층의 존재
    - 은닉층의 개수는 ‘층의 깊이’
    - 노드의 수는 ‘층의 너비’
- Loss Function (손실함수) 을 사용하여 올바른 가중치를 찾을 수 있음
    - 둘 중 더 좋은 결정경계를 찾는 것
    - 최적의 결정경계를 찾기 위해 손실함수를 쓰는 것이다.
    - MSE(Mean Squared Error); 평균제곱오차를 사용해 오차가 적은 경계가 일반적으로 더 좋은 결정 경계

## 최적 해 계산

- 경사 하강법과 오차 역전파를 활용해 최적의 값을 찾음
    - 순전파 →  손실 계산 → 역전파 순으로 진행
    - 순전파 : 다층신경망 출력값 계산식 정의 및 입력 데이터부터 출력 값까지 계산
- 오차 역전파
    - 초기 w를 랜덤한 값으로 초기화
    - 가중치를 사용해 출력값이 나오면, 우리는 정답 (데이터) 을 알고 있으니 에러 차이 검출
    - 그 에러 차이를 기울기로 표현
    - 미분 연산을 통해 기울기 계산
- 오차 역전파 과정에서 선형 구조를 써버리면 미분 과정에서 항상 상수를 출력하므로 학습이 진행되지 않음.
- ReLU 활성화 함수
    - f(x) = max(0, x)
    - 0보다 작다면 반드시 0으로 출력

---

- 경사 하강법을 통해 시작점부터 최적 해를 구할 때까지 학습
    - 반복적인 모델 학습
    - 학습률에 따라 모델 학습에 긍정 / 부정적 영향이 있을 수 있음

- 이진 분류가 아닌 다중 클래스 분류 시에는 **교차 엔트로피**를 사용
    - 엔트로피 : 확률 분포 P(x)에 대한 불확실성의 척도
    - 정보량 낮음 = 특별하지 않음 = 엔트로피 낮음 = 구분이 쉬움
    - 실제 데이터의 확률 분포와 학습된 모델이 계산한 확률 분포의 차이를 최소화하는 방식

---

# 인공지능 분류모델

- 대표적인 사례로 **RNN**, **CNN**이 해당됨
- RNN은 시계열 데이터 분류의 대표적인 모델
- CNN은 대표적인 이미지 분류 모델
- 최근에는 Transformer(트랜스포머) 기반의 분류 기술이 다수 등장함

## RNN

- Recurrent Neural Network : 시계열 데이터 대표 분류 모델
- 시계열 데이터 : 순서 정보가 존재하는 연속적인 데이터. 텍스트, 음성, 생체신호
- 하나의 유닛을 반복적으로 접근하여 활용, 데이터의 길이가 길어지는 경우 초기 입력정보를 잊어버리는 현상이 발생
- 학습이 길어지면 초기 데이터를 잊어버리는 현상이 생겨 LSTM, GRU가 후속 개발
- 시계열 데이터를 활용할 땐 특정 길이만큼 잘라서 활용해야 함
- 자연어 처리, 음성인식, 음악 생성 등 시계열 데이터 예측

## CNN

- Convolutional Neural Network : 이미지 분류의 대표적인 모델
- 컨볼루션 연산으로 이루어진 합성곱 층과 활성화 함수 등으로 이루어짐.
- 분류 시에는 MLP 활용
- 이미지, 동영상 뿐 아니라 생체신호 데이터를 이미지로 변환하여 인공지능 모델 개발
- 가로세로 동일한 크기로 원본 이미지를 리사이즈, 합성곱 커널로 활용
    - 커널은 이미지로부터 특징을 추출하기 위한 가중치 행렬
    - 커널의 집합을 필터라고 함
- 커널을 픽셀단위로 이동시키며 곱을 하고, 더하는 과정을 반복
- 특정 맵 : 합성곱의 결과로부터 얻어지는 이미지.
- 스트라이드 : 커널의 이동 거리 (1 pixel)
- 컨볼루션 연산이 해당 이미지의 넓은 부분을 특정한 특징으로 추려내 저화질로 만드는 것
- 즉, 사람 얼굴이 인풋되었다면 커널 연산을 적용하고, 그 모든 값들의 합 숫자가 합성곱
    - 이 데이터들을 통해서 어떤 이미지가 들어갔을 때 사람 얼굴이냐 아니냐를 분류
- 패딩 없이 합성곱 연산을 진행했다면 입력 이미지에 비해 결과가 작아짐
    - 계속해서 반복할 경우 점점 작아지므로, 바깥쪽에 패딩을 추가해 작아지지 않게 하는 것
    - 바깥쪽에 0만 채우는 것을 제로패딩(Zero Padding)이라고 함
- 모델의 앞 부분에 가깝다면 지역 특징정보를 학습
- 모델의 뒷 부분에 가깝다면 전역 특징정보를 학습
- 결국 분류 문제를 푼다면 MLP를 사용해서 예측 결과를 뽑아냄
- 차원 축소를 위한 pooling layer
    - 주로 활용되는 max pooling : 정의된 커널(2x2) 내에서 가장 큰 응답 값만 다음 단계로 전달
    - 특정 이미지에서 일정 부분을 잡고, 그 중에서 가장 큰 수만 남기고 축소
- 이미지 분류기의 평탄화 (1차원 벡터로 변환)
    - 평탄화 층에서 MLP층의 입력으로 사용하도록, 이미지를 1차원 벡터로 변환
- CNN 모델 학습 과정
    - 모델 정의 → 데이터 호출 및 데이터 증강 → 손실 계산 → 오차 역전파 및 최적화 → 원하는 만큼 반복 → 학습 종료
- 데이터 증강
    - 크롭핑, 패딩, 대칭 회전
    - 이미지에 여러 변형을 주어 이미지 개수를 늘리는 기법.
    - 크롭핑 : 이미지의 일정 부분을 도려내는 기법. 불필요한 부분 잘라내기.
    - 패딩 : 이미지 특정 영역을 0 혹은 아무 값으로 채우는 기법.
    - 대칭 회전 : 이미지 뒤집기
- 정규화 과정
    - 이미지마다 적색 / 녹색 / 청색의 컬러 분포가 굉장히 특징적임
    - 빨간색 차 이미지를 넣으면, 차라고 분류하는게 아닌 빨간색으로 분류할 가능성이 있음
    - 그러므로 색 분포를 수정하는 것. 모두 RGB를 모두  0.5로 수정하는 것
- 드롭 아웃
    - 오버피팅을 피하기 위해 가중치의 일부를 0으로 만드는 기법
    - 데이터가 너무 많다보면 학습 데이터에 대한 정확도가 너무 높아져서 테스트 데이터를 제대로 맞추지 못하게 될 수도 있음
    - 다음 층으로 이동하는 선을 몇 개 잘라서 완만하게 만듬
- CNN의 대표적인 모델인 VGG-16 구조
    - 원본 이미지를 계속해서 줄여나가 크기를 줄이고
    - 평탄화 작업을 통해 1차원 벡터 값으로 변환
    - 마지막에 1x1x1000 블록으로 만들고, 이것이 소프트맥스 층

## Transformer

- Attention is all you need(NeurlPS 2017, 10만 회 이상 인용된 논문)
- 시계열 데이터의 순서정보와 무관하게 한 번에 정보를 처리할 수 있는 구조
- 인코더 - 디코더 구조로 이루어져있음
- 순서 없이 한 번에 입력, 바로 출력
    - 분류 모델로 사용할 것이면 인코더 바로 뒤에 MLP로 끝.
    - 생성형 모델로 사용할 것이라면 인코더 뒤에 디코더
- 시계열 데이터 뿐만 아니라 이미지에도 활용 가능
    - 이미지를 패치 단위로 여러개를 잘라서, 한 번에 삽입
    - 패치 순서를 같이 입력해주고, 인코더에서 한 번에 처리
    - MLP 헤드를 통해 분류에 활용
- 단,  모델의 크기가 매우 커야 하고, 학습 데이터도 굉장히 많아야 함

---

## 인공지능 인식모델

- 얼굴인식, 스피치 인식 등 작업별 기술이 개별적으로 발전함
- 가짜얼굴을 만들어 공격하는 기술, 그걸 검출하고 방어하는 기술이 발전되고 있다.
- 스피치 인식(ASR) 음성 신호를 모델링하기 좋은 형태로 변환하여 트랜스포머 활용
    - 트랜스포머의 인코더 부분만 활용하는 BERT 기반의 모델이 증가함

## 인공지능 분할모델

- 이미지나 비디오 안에서 특정 개체들을 픽셀 단위로 레이블을 매겨주는 작업
- 이미지 전체가 무엇인지 판별이 아닌, 이미지 내의 여러 객체들을 구별
- 세밀한 결괏값을 얻어냄
- SAM(Segment Anything Model) @META
    - 최근에 나온 분할모델
    - 간단한 사용자의 인터랙션으로 이미지를 분류하고 잘라줌
    - Heavy Weight 이미지 인코더를 사용 (트랜스포머 중 인코더만 사용한 BERT 기반)

## 인공지능 생성모델

- GAN : 적대적 학습 기반 생성 기술
- Diffusion models : 이미지 ↔ 노이즈 간 단계적 변환을 통한 생성기술
    - 데이터를 통해 노이즈 생성, 노이즈를 통해 새로운 데이터 생성

### GAN

- 생성자 → 생성자가 만들어낸 가짜 이미지 + 진짜 이미지 → 감별자 → 진짜?가짜?
- 생성자의 학습, 감별자의 학습을 통해 강화
    - 감별자의 학습을 통해 가짜 이미지 출력이 0이 되도록 학습함
    - 생성자의 학습을 통해 가짜 이미지 출력이 1이 되도록 학습함
    - 즉, 서로가 다른 방향으로 학습하며 언젠가는 진짜 사물과 유사한 이미지를 생성
- GAN 학습을 할 때, 손실함수 그래프를 확인했을 때 지글지글하고 지그재그가 나와야 함

### Diffusion Models

- 음성, 이미지, 텍스트 데이터 모두 적용 가능한 데이터 → 노이즈 → 데이터 생성
- Forward Diffusion Process : 이미지에 노이즈 추가 학습
- Reverse Diffusion Process : 노이즈로부터 데이터를 복원하는 과정 학습

### 평가지표

- 생성 모델에 대해 무엇이 정답이다라는 정확한 절대적 값이 없음
- 따라서 FID를 통해 생성한 이미지가 얼마나 진짜같은지 가짜같은지 평가
- 생성한 이미지가 얼마나 진짜같은지 평가하는 지표
- 원본 이미지 데이터 셋과 생성된 이미지 데이터셋 사이의 통계적 거리를 측정
- 공식 암기할 필요 없음
- 물론 FID 값이 잘 나와도 실제론 아닐 수 있으므로 한 번 돌려봐야 함