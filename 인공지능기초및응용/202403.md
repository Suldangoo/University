# 1주차

- 논문 / 프로젝트 발표 중 택 1, 모두 참여 시 +5점
    - 프로젝트 : 인공지능 모델 및 활용기술 개발
    - 논문 : 학술대회명, 제목
    - 관련 연구, 기존 기술 문제점, 기존 기술 극복법, 신규 기술 한계점, 질의응답 모두 포함
    - 발표 시간 15분, 질의응답 5분

- 논문의 경우 23년도 이후 AI관련 학술대회 정규논문으로 제한
    - https://openaccess.thecvf.com/menu
    - 정규논문으로 제한, 워크숍 논문 발표 시 3편 이상 발표
- 프로젝트 기존기술 : 23년도 이후 AI관련 학술대회 정규논문으로 제한
    - 가급적 소스코드가 공개된 기술로
    - 소스코드 구현

- 수학, 머신러닝에 대한 기본 지식이 필요

- 논문에 나오는 용어들은 라틴어 약어이므로 PPT 참고
- 읽는 순서
    1. 제목
    2. Abstract (초록)
    3. Conclusion (결론)
    4. Result (결과)
    5. Introduction (서론)
    6. Method & Result (방법 및 결과)
- 논문의 제목 및 초록을 통해 다음과 같은 내용 파악 후 상세 읽기
    - 대표 주제
    - 기존 연구의 문제점
    - 간략한 아이디어
    - 실험에 사용한 데이터
    - 결과 성능
    - 한계점
- 논문 구글 스칼라에 검색하여 인용 수 확인
- 서론의 경우엔 간단한 개념만 요약해 보기

# 2주차

## 인공지능의 역사

- 인공지능(AI)의 정의 : 인간의 학습능력, 추론능력, 지각능력을 인공적으로 구현하려는 컴퓨터 과학의 세부분야 중 하나
    - AI 내부 개념으로 머신 러닝
    - 머신 러닝 내부 개념으로 딥 러닝
    - 딥 러닝 내부 개념으로 파운데이션 모델
    - 파운데이션 모델 내부 개념으로 LLM
- 1950년 컴퓨터의 시초인 **튜링머신**을 앨런 튜링이 개발
    - 기계가 인간과 얼마나 유사한 응답을 내는지 확인하기 위한 튜링 테스트를 고안
    - 사람과 원숭이 사진을 보고 어떤게 사람인지 대답해내는 것과 비슷
- 1956년 존 매카시가 **인공지능**이라는 용어를 정의
- 1957년 인공 신경망 모형의 하나인 **퍼셉트론**(Perceptron) 등장
    - 입력 데이터에 가중치를 곱하고 활성화함수 통과 후 출력 값을 내는 구조
- 초기 컴퓨터는 bit 연산을 통해 데이터를 처리
    - 1과 0으로 이루어진 전기가 흐르냐 안 흐르냐
    - 대표 연산자로 NOT, AND, OR, XOR
    - 퍼셉트론으로는 AND, OR을 해결할 수 있으나 XOR을 해결할 수 없었음
- 1986년 **다층 퍼셉트론**(Multi Layer Perceptron; **MLP**) 등장 (제프리 힌튼)
    - 입력층과 출력층 사이에 은닉층을 추가해 기존에 풀지 못했던 XOR 문제 해결
- 퍼셉트론과 오차역전파 등장 이후 CNN 및 RNN 기반의 인공지능 기술이ㅣ 발전함
- 2012년 ILSVRC 대회에서 CNN 기반 모델인 AlexNet으로 1위를 차지 (제프리 힌튼)
    - 2015년부터 이미지 분류 점수가 인간을 추월하게 됨
- 2014년 **GANs**의 등장으로 인공지능기반 생성모델의 잠재력을 확인
    - 서로 다른 목적을 가진 두 네트워크 학습인 적대적 학습
    - 이때부터 가짜 데이터를 만들어내기 시작 (사람의 얼굴을 생성함)
    - 이후 GAN 기반의 생성기술이 급격히 발전해 Diffusion 기반의 기술로 대체되었다
- 2017년 **Transformer**의 등장으로 자연어 분류 및 생성 기술에도 급격한 기술 발전
    - ChatGPT도 Transformer 기반 기술 중 하나
    - 이후 모든 텍스트 기반의 인공지능 기술은 거의 모든것이 트랜스포머를 기반으로 둔 기술
- 2024년 CES에서 소개된 IT트랜드 On-device AI
    - 네트워크 연결 없이 반도체 칩으로 AI 모델을 구동시키기 위한 기술
    - 갤럭시 S24부턴 AI 실시간 번역기능을 탑재해 출시
    - AI 기술을 이곳저곳에서 쓰고싶어도 대부분 비용 문제가 발생해서 사용이 어려움
    - 기술은 있지만 하드웨어가 없어서 사용을 못하고 있었는데 온디바이스가 되면 해결됨

## 인공지능 기초 및 용어

- 규칙 기반(Rule-based) 인공지능
    - 학습이 불필요함
    - A를 누르면 B를 실행
- 학습기반(Learning-based) 인공지능
    - 머신러닝, 딥러닝은 학습기반 기술에 포함
    - 데이터(지식)를 기반으로 특성 추출 및 분류(분석)를 통해 결과를 출력하는 방식
    - 인간이 직접 특성을 추출하면 머신 러닝, 컴퓨터로 추출하면 딥러닝

- 정형 데이터 (Structured Data)
    - 정해진 틀/형태에 맞게 저장된 데이터
- 반정형 데이터
    - 데이터 모델을 따르지는 않는 형태이나 구조화된 데이터
- 비정형 데이터 (Unstructured Data)
    - 특정 형태나 데이터 모델 없이 저장된 데이터

- Zero-shot Learning
    - 학습하지 않은 범주의 데이터를 분류
- One-shot Learning
    - 1개의 샘플만 학습하여 사용하는 모델
- Few-shot Learning
    - N개 (주로 1~5) 데이터만 사용하여 학습한 모델

- Classification (이미지, 오디오, 텍스트 분류)
    - 데이터를 미리 정의된 카테고리로 분류
    - 내일 날씨는 추울까 / 따듯할까?
- Regression (회귀, 수치 예측)
    - 데이터에 기반해 연속적인 수치(Value)를 예측
    - 내일 날씨는 몇 도일까?

- Pattern Recognition (얼굴, 지문, 음성인식)
    - 데이터에서 패턴이나 규칙을 식별
- Attribute Classification (속성정보 분류)
    - 객체의 여러 속성을 분류하여 정보를 구분

- Clustering (군집화, 비슷한 그룹끼리 뭉침)
    - 유사한 특성을 가진 데이터 포인트들을 그룹화
    - 여러가지 얼굴 인식 포인트가 있을 때 다르게 찍힌 얼굴도 동일인물이라고 판단하는 범위
    - 아이폰 갤러리에 사람 얼굴 그룹
- Detection (객체 검출 = 위치 + 레이블정보 분류)
    - 객체의 위치를 찾고 해당 객체를 분류
    - YOLO로 사진 안에서 사람, 자동차 등 식별
- Localization (상세한 위치 파악)
    - 정보의 정확한 위치를 식별
    - 어느 한 사물에서 일부 흠집같은 아주 세밀한 부분, 비정상 영역을 정확하게 식별

- Generation (생성)
    - 이미지, 텍스트, 오디오, 비디오 생성 등 데이터를 생성
- Translation (변환, text2img, img2img, TTS)
    - 생성 기술 중 한 가지 방식으로, 한 형식의 데이터를 다른 형식으로 변환
    - TTS (Text to Speach)

- Supervised Learning (지도학습)
    - 레이블이 지정된 훈련 데이터를 사용하여 모델을 학습
    - 분류해야할 테이블이 있고, 분류될 개체들의 각각 정답들이 모두 주어져있을 때 분류하기
- Semi-Supervised Learning (반지도학습)
    - 소량의 레이블이 지정된 데이터와 대량의 레이블이 없는 데이터를 함께 사용하여 모델 학습
    - 몇몇 데이터들은 정답이 있으나, 몇몇 데이터는 알려주지 않았을 때 그걸 분류해냄
- Unsupervised Learning (비지도학습)
    - 레이블이 지정되지 않은 데이터를 사용해 모델 학습
    - 전혀 정답을 알려주지 않아도 특징을 잡아내 연관된 것들끼리 분류

- Self-Supervised Learning (자기지도학습)
    - 데이터 내에서 레이블을 스스로 만들어 해당 레이블 데이터를 활용하여 모델학습
    - 이전 정보에서 다음으로 이어지는 단어들을 수집, 예측
    - Mask된 영역에 무엇이 들어갈지 예측
- Reinforcement Learning (강화학습)
    - 환경과의 상호작용을 통해 얻은 보상을 기반으로 최적의 결정 또는 경로 학습
    - 반복적으로 학습하며 더 나은 방향을 찍을 때마다 좋은 보상을 지급
- Continual Learning (연속학습)
    - 모델이 새로운 데이터 또는 작업을 지속적으로 학습하면서 과거에 학습한걸 잊지 않도록 학습
    - 학습 테스크를 나누어 1번부터 50번까지 학습, 다음엔 1번부터 60번까지 학습…

- Pre-train (사전학습)
    - 대용량 데이터 기반의 모델 학습
    - 빅데이터를 활용하여 하나의 모델을 생성
- Fine-Tuning (파인튜닝)
    - 대용량 데이터 기반 모델을 활용, 일반적으로는 소규모 데이터로 목적에 맞게 모델 재학습
    - 주목할 부분만 특별히 해석하거나, 필요한 데이터를 추가로 학습하는 등 미세 조정
    - 층 100개중 앞 30층만 변형, 뒤 70층은 고정하는 방식
    - 전이학습(Transfer Learning)이라는 미세 조정, 파인 튜닝

- Split (데이터 분할)
    - 인공지능 모델 개발 시 전체 데이터를 학습, 테스트 데이터로 구분하여 사용
    - 비율은 정해지지 않았으며 학습, 검증, 테스트로 구분하는 경우도 있고 검증은 모델 수렴을 확인하는데 사용함
    - 대부분의 공인 데이터는 학습  데이터와 테스트 데이터를 별개로 구분
- K-fold-cross-validation
    - 데이터를 K분할하여 교차검증
    - 이러면 모든 데이터에 대해 학습 / 테스트 구분이 가능해짐
    - 즉, 우연히 일정 방향으로 일반화된 결과가 나오지 않게 됨
        - Split마다 모델이 각각 하나씩 만들어짐
        - 여러 모델들을 만들어 평균 정확률이 가장 높은 것을 사용

---

## Numpy

- 임포트 구문

```python
import numpy as np
```

## Tensor

- 파이토치에서 텐서(Tensor)는 기본적인 수치 연산을 위한 주요 데이터 구조
- 임포트 구문

```python
import torch
```