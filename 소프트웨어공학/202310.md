# ■ 4주차 (10월 5일)

- 클래스  다이어그램
    - 하얀 삼각 화살표 : 일반화 (부모로부터 상속받아 생성)
    - 하얀 마름모 화살표 : 집합 (부모가 사라져도 활용 가능)
    - 검은 마름모 화살표 : 합성 (부모가 사라지면 본인도 파괴)

## 인공지능 기초

- 인공지능은 요즘 언어 모델 / 음성 / 비전 기술로 나뉜다
- 인공지능 : 인간의 학습 능력, 추론 능력, 지각 능력을 인공적으로 구현하는 기술
    - 인간의 뇌에 존재하는 시냅스와 인간이 가진 정보량은 비례관계
    - 시냅스를 따라 만든 AI 파라메터가 많을 수록 성능이 향상됨
- AI는 ML(머신 러닝)과 DL(딥 러닝)을 모두 포함한다

### 머신 러닝

- 머신 러닝은 컴퓨터가 명시적으로 프로그래밍되지 않아도 학습할 수 있는 능력을 갖추도록 하는 알고리즘과 기술의 집합.
- 딥러닝을 포함하는 넓은 범위를 가지며, 딥러닝 이외에도 다양한 학습 알고리즘을 포함
- 대표 기술 : SVM, Logistic Regression 등 (AI로는 여겨지지 않는 기술)

### 딥 러닝

- 머신 러닝의 한 분야로, 인공 신경망을 기반으로 복잡한 비선형 문제를 해결하는 방법론
- 대량의 데이터와 계산 능력을 요구, 많은 데이터와 모델의 크기가 성능을 좌우함
- 대표 기술 : CNN, RNN, Transformer 등 (AI라고 여겨지는 기술)

### 딥 러닝 모델

- 입력층, 다계층으로 구성된 은닉층, 출력층을 이루고 있는 모델
- 입력층 1개, 은닉층 N개, 출력층 1개

### 인공지능 모델의 개발 과정

- 인공지능 모델 개발 과정
    - 다량의 데이터를 사전 학습하여 사전 학습된 모델 생성 (GPT의 P)
    - 태스크맞춤형 데이터를 넣은 파인 튜닝을 통해 맞춤형 모델 생성
- 순전파(Forward Propagation) 와 역전파(Back Propagation) 를 통한 모델 학습 과정
    - 순전파 : 데이터에 가중치를 곱하여 예측치를 계산
    - 역전파 : diff(예측치 - 정답)을 활용하여 가중치 업데이트
- 모델 학습 과정
    - 데이터 수집 및 전처리 → AI 모델 학습 → AI 모델 패키징 → AI 모델 검증 → 실제 환경에 모델 적용 → 유지보수 및 모니터링

- 인공지능 모델 개발에 활용되는 데이터 형태
    - 정형 데이터 : 구조화된 형태로 값이 존재 (DB 등)
    - 반정형 데이터 : 구조화된 형태지만 연산이 불가능 (XML, JSON 등)
    - 비정형 데이터 : 형태가 없고, 연산도 불가능 (텍스트, 영상, 음성 등)

### 인공지능 기술의 발전 현황

- 인공지능 모델 개발에 활용되는 기술은 오래전부터 개발되기 시작함
    - 1940년부터의 전자두뇌, 단일계층 신경망 ~ XOR 등등
- 2012년 알렉스넷부터 인공지능 기술이 발전도기 시작
- GPU의 발전에 따라 인공지능이 점점 성공을 거둠
    - GPU 사용률이 높을 수록 인공지능의 에려율이 줄어듦
- 인공지능 모델 학습용 데이터가 날이 갈수록 방대해짐
- 그에 따라 인공지능 모델의 크기가 540빌리언까지도 커짐

---

## 자연어처리 (NLP) 기초

- 인간과 매우 유사한 방식으로 텍스트 및 음성 언어를 이해하는 능력 부여
- 자연어 데이터는 사람이 알아보긴 쉽지만 그대로 기술에 활용하긴 어려우므로, 전처리 과정을 통해 벡터화된 정보로 활용
    1. 토큰화 (단어나 문자를 분할)
    2. 단어 집합 생성 (중복 제거, 고유 인덱스 부여)
    3. 정수 인코딩 (고유한 정수를 매핑)
    4. 패딩 (동일한 길이로 맞춤)
    5. 벡터화 (원핫 인코딩, 워드 임베딩 등으로 자연어 표현)
- 원핫 인코딩 (One-hot Encoding)
    - 1 또는 0으로 구성된 벡터, 단 하나의 값만 1이고 나머지 다 0인 벡터
- 단어 임베딩 (Word Embedding)
    - TF-IDF (횟수기반 임베딩 대표방법)
    - Word2Vec (추론기반 임베딩 대표방법)
- 원핫 벡터와 임베딩 벡터의 차이점
    - 원핫 벡터
        - 고차원 (단어 집합의 크기)
        - 다른 표현 : 희소 벡터의 일종
        - 표현 방법 : 수동
        - 값의 타입 : 0과 1
    - 임베딩 벡터
        - 저차원
        - 다른 표현 : 밀집 벡터의 일종
        - 표현 방법 : 훈련 데이터로 학습
        - 값의 타입 : 실수
- 인공신경망을 이용한 자연어 처리 : RNN
    - 언어 데이터는 순서 정보를 포함하고 있으므로, 이전 정보와 향후 정보를 반영하는 RNN 계열 모델을 사용하여 자연어 처리에 활용함
    - hidden layer를 활용해 한 문자가 주어지면 다음 순서의 문자로 갈 수 있도록 모델을 설계
- 다양한 입/출력 형태를 구성하여 목적에 맞게 활용
    - one - to one
    - one - to - many
    - many - to one
    - many -to many
- RNN의 기울기 소실 문제
    - 딥러닝 특성상 히든 레이어의 수가 많고, 반복되는 단계가 깊어질수록 입력층에 가까운 벡터들이 제대로 학습되지 못함
    - 따라서 깊이를 무한정으로 둘 수 없었음
- 위 문제를 해결하는, 언어에 대한 정보를 더 잘 학습하기 위한 LSTM, GRU
    - 장기의존성 문제 해결을 위해 몇 가지 기술을 추가하여 자연어 처리에 활용
    - 과거 정보를 얼마나 유지할지, 새로 입력된 정보는 얼만큼 활용할지, 두 정보를 계산하여 나온 출력 정보를 얼마만큼 넘겨줄지 결정
    - 그럼에도 데이터가 길어지면 잊어버리는 문제는 여전함
        - → 트랜스포머의 등장 (GPT의 T)

---

## LLM (Large Lange Models)

- LLM : 수십억 또는 수조 개의 파라메터를 포함하는 대규모 언어 모델
    - 단순히 엄청나게 많은 데이터를 학습한 AI 모델
    - 대표적으로 OpenAI의 GPT-3

### 트랜스포머

- 기존 자연어처리 모델 구조와 달리, 다양한 인코더 - 다양한 디코더 형태로 구성된 구조
- 셀프 어텐션, 포지셔널 인코딩을 통해 처리 성능 향상
    - 단어와 단어 사이의 연관관계, 단어의 순서와 위치정보 학습
- 트랜스포머 구조를 활용하는 기술 탄생 : BERT, GPT
- BERT
    - 트랜스포머의 인코더 구조를 활용한 언어모델, 사전학습된 파인튜닝 단계
    - 사전학습된 거대 모델들은 최근 Foundation Model이라고 불림
    - 성능 향상을 위한 학습 방법들을 제안
        - 중간중간 MASK 지정, 비어있는 공간 채워 모델의 성능 향상
        - 자연어 문장의 이빨 하나를 빼놓고 입력하면 그 이빨을 추론
- GPT
    - 트랜스포머의 인코더 - 디코더 구조를 모두 활용하는 거대 언어모델
    - ChatGPT를 통해 최근 알려졌지만 2018년도부터 지속되어 개발
    - GPT-3는 175빌리언의 텍스트를 썼지만, GPT-4부터는 알려주지 않음
    - GPT 개발용 Task (GPT뿐만 아니라 다양한 인공지능에서 쓰임)
        - Zero-shot : 학습되지 않은 처음 보는 문제를 맞추는 Task
        - One-shot : 하나의 정답만 보여주고 문제를 맞추는 Task
        - Few-shot : 몇 가지 답을 보여주고 문제를 맞추는 Task
    - GPT를 잘 쓰려면 Few-shot Task로 문제를 내면 원하는 답이 더 잘 나옴
        - 만들고자 하는 코드에 대한 지시를 하고, 잘 만들어진 코드 예시 또는 포맷을 함께 제공
    - GPT의 대항마 LLaMA
        - 라마는 ChatGPT-3에 비교하면 모델의 크기는 상당히 줄고 성능이 개선
        - 오픈소스로 공개하여, 업스테이지 등 여러 기업들이 라마를 기반으로 개발중

## 생성 모델 활용 사례

- 언어 생성
    - 자연어 생성, 코드 작성
- 이미지 생성
    - GAN 또는 SD기반의 모델을 사용하여 이미지 / 동영상 생성
    - 딥페이크
- 음악 및 오디오 생성
    - 음악 생성 및 음성 생성
- 번역, 광고
- AUTO-GPT
    - 인간처럼 생각하고 행동 무한반복하는 장기행동
    - 개발환경 구축, 라이브러리 설치, 코딩 등등
    - 심지어 피자가게 가서 피자 주문해줌